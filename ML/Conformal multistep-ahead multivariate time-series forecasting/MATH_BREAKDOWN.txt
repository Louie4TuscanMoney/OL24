CONFORMAL PREDICTION: MATHEMATICAL BREAKDOWN
================================================================================
Source: Schlembach et al., "Conformal Multistep-Ahead Multivariate Time-Series
Forecasting", Proceedings of Machine Learning Research 179:1-3, 2022

AUTHORS: Filip Schlembach (Maastricht), Evgueni Smirnov (Maastricht), 
         Irena Koprinska (Sydney)

PROBLEM STATEMENT
--------------------------------------------------------------------------------
Task: Multistep-Ahead Multivariate Time Series Forecasting with Uncertainty

Given: Time series observations o_j ‚àà ‚Ñù^d for j = 1,...,t
Goal: Predict o_j for j = t+1,...,t+h (h steps ahead, d dimensions)
      with prediction intervals having coverage guarantee

Challenge: Time series violates exchangeability assumption
- Temporal dependence between observations
- Distribution shifts over time (as shown in ELEC2 dataset experiments)
- Need adaptive weighting to minimize coverage loss


CORE MATHEMATICAL FRAMEWORK
================================================================================

1. STANDARD CONFORMAL PREDICTION (EXCHANGEABLE CASE)
--------------------------------------------------------------------------------

Nonconformity Score:
    s_i = |y_i - fÃÇ(x_i)|
    
    Where fÃÇ trained on all data except (x_i, y_i)

Prediction Region (Interval):
    C(x_{n+1}) = [fÃÇ(x_{n+1}) - q_{1-Œ±}, fÃÇ(x_{n+1}) + q_{1-Œ±}]
    
    Where q_{1-Œ±} = quantile_{1-Œ±}({s_1, s_2, ..., s_n})

Coverage Guarantee (Exchangeable):
    P(y_{n+1} ‚àà C(x_{n+1})) ‚â• 1 - Œ±
    
    Holds exactly under exchangeability assumption


2. SPLIT CONFORMAL PREDICTION
--------------------------------------------------------------------------------

Split Data:
    Training set: D_train = {(x_i, y_i)}_{i=1}^m
    Calibration set: D_cal = {(x_i, y_i)}_{i=m+1}^n

Algorithm:
    Step 1: Train fÃÇ on D_train only
    Step 2: Compute scores on D_cal:
        s_i = |y_i - fÃÇ(x_i)| for i = m+1, ..., n
    Step 3: Quantile:
        qÃÉ = ‚åà(1-Œ±)(n-m+1)‚åâ-th smallest score in {s_{m+1}, ..., s_n}
    Step 4: Prediction set:
        C(x_{test}) = [fÃÇ(x_{test}) - qÃÉ, fÃÇ(x_{test}) + qÃÉ]

Coverage Guarantee:
    P(y_{test} ‚àà C(x_{test})) ‚â• 1 - Œ±
    
    Exact coverage under exchangeability


3. TIME SERIES CHALLENGES
--------------------------------------------------------------------------------

Exchangeability Violation:
    y_t and y_s NOT exchangeable for t ‚â† s
    ‚Üí Standard conformal guarantees don't hold

Temporal Dependence:
    Correlation structure: Cov(y_t, y_s) ‚â† 0 for |t-s| > 0
    
Œ≤-Mixing Condition (Weak Dependence):
    Œ≤(m) = sup_{t} sup_{A ‚àà œÉ(y_1,...,y_t), B ‚àà œÉ(y_{t+m},...)} |P(A‚à©B) - P(A)P(B)|
    
    Assumption: Œ≤(m) ‚Üí 0 as m ‚Üí ‚àû (mixing)
    
    Rate: Œ≤(m) ‚â§ C¬∑m^{-Œ≥} for some Œ≥ > 0

Modified Coverage Guarantee:
    |P(y_{n+1} ‚àà C(x_{n+1})) - (1-Œ±)| ‚â§ O(1/‚àön + Œ≤(m))
    
    Where:
    - n = calibration set size
    - m = mixing lag
    - Coverage error decreases with n


4. NONEXCHANGEABLE MULTISTEP CONFORMAL (nmtCP)
--------------------------------------------------------------------------------

Multistep Forecast Horizon:
    Predict h steps ahead: ≈∑_{t+1:t+h} = (≈∑_{t+1}, ..., ≈∑_{t+h})
    True values: y_{t+1:t+h} = (y_{t+1}, ..., y_{t+h})

Nonconformity Score (Max Norm):
    s_t^{(h)} = max_{j=1,...,h} |y_{t+j} - ≈∑_{t+j}|
    
    Alternative (L2 Norm):
    s_t^{(h)} = ‚àö(Œ£_{j=1}^h (y_{t+j} - ≈∑_{t+j})¬≤)

Prediction Region (Multivariate):
    C_t^{(h)} = {(y_{t+1}, ..., y_{t+h}) : max_j |y_{t+j} - ≈∑_{t+j}| ‚â§ qÃÉ_{1-Œ±}}
    
    Hypercube centered at point forecast

Coverage (Simultaneous):
    P(y_{t+1:t+h} ‚àà C_t^{(h)}) ‚â• 1 - Œ± - O(1/‚àön + Œ≤(m))


5. ADAPTIVE/WEIGHTED CONFORMAL FOR NON-STATIONARITY
--------------------------------------------------------------------------------

Time-Weighted Scores:
    w_t = exp(-Œª(n-t))  or  w_t = exp(-(n-t)¬≤/(2œÑ¬≤))
    
    Where:
    - Œª, œÑ = decay parameters
    - Recent observations weighted more heavily

Weighted Quantile:
    qÃÉ_{1-Œ±}^w = inf{q : Œ£_{i=1}^n w_i¬∑ùüô{s_i ‚â§ q} ‚â• (1-Œ±)¬∑Œ£_{i=1}^n w_i}

Adaptive Prediction Region:
    C_t^{(h)} = [≈∑_{t+j} - qÃÉ_{1-Œ±}^w, ≈∑_{t+j} + qÃÉ_{1-Œ±}^w]  for j=1,...,h

Properties:
    - Adapts to distribution shift
    - Tracks non-stationarity
    - Coverage maintained approximately


6. MULTIVARIATE TIME SERIES
--------------------------------------------------------------------------------

Multivariate Forecast:
    ≈∑_{t+1:t+h} ‚àà ‚Ñù^{h√ód}  where d = number of features
    
Joint Nonconformity Score:
    s_t^{joint} = max_{j=1,...,h} max_{k=1,...,d} |y_{t+j,k} - ≈∑_{t+j,k}|
    
    ‚Üí Single quantile for all dimensions

Marginal Nonconformity Scores:
    s_t^{(k)} = max_{j=1,...,h} |y_{t+j,k} - ≈∑_{t+j,k}|  for k=1,...,d
    
    ‚Üí Separate quantile per feature

Joint Prediction Region:
    C_t^{joint} = {y : max_{j,k} |y_{j,k} - ≈∑_{t+j,k}| ‚â§ qÃÉ^{joint}}
    
    Coverage: P(y_{t+1:t+h} ‚àà C_t^{joint}) ‚â• 1 - Œ±

Marginal Prediction Regions:
    C_t^{(k)} = {y_k : max_j |y_{j,k} - ≈∑_{t+j,k}| ‚â§ qÃÉ^{(k)}}  for each k
    
    Coverage (per feature): P(y_{t+1:t+h,k} ‚àà C_t^{(k)}) ‚â• 1 - Œ±

Bonferroni Correction (Simultaneous Coverage):
    Use Œ±_k = Œ±/d for each marginal region
    
    ‚Üí P(‚àÄk: y_{t+1:t+h,k} ‚àà C_t^{(k)}) ‚â• 1 - Œ±


ALGORITHMS
================================================================================

ALGORITHM 1: Split Conformal for Time Series
--------------------------------------------------------------------------------
Input: Calibration set {(x_t, y_{t+1:t+h})}_{t=1}^n, model fÃÇ, Œ± ‚àà (0,1)
Output: Prediction function with intervals

1. FOR t = 1 to n DO:
     ≈∑_{t+1:t+h} = fÃÇ(x_t)
     s_t = max_{j=1,...,h} |y_{t+j} - ≈∑_{t+j}|
   END FOR

2. Sort scores: s_{(1)} ‚â§ s_{(2)} ‚â§ ... ‚â§ s_{(n)}

3. Compute quantile index: k = ‚åà(1-Œ±)(n+1)‚åâ

4. Set qÃÉ = s_{(k)}

5. PREDICT(x_test):
     ≈∑ = fÃÇ(x_test)
     RETURN [≈∑_j - qÃÉ, ≈∑_j + qÃÉ] for j=1,...,h

Complexity: O(n¬∑h) for calibration, O(1) for prediction


ALGORITHM 2: Adaptive Weighted Conformal
--------------------------------------------------------------------------------
Input: Calibration set, model fÃÇ, Œ±, decay œÑ
Output: Adaptive prediction intervals

1. FOR t = 1 to n DO:
     s_t = max_{j=1,...,h} |y_{t+j} - fÃÇ(x_t)_j|
     w_t = exp(-(n-t)¬≤/(2œÑ¬≤))
   END FOR

2. Compute weighted quantile:
     sorted_idx = argsort(s)
     cum_weights = cumsum(w[sorted_idx])
     total_weight = sum(w)
     k = argmin{cum_weights ‚â• (1-Œ±)¬∑total_weight}
     qÃÉ_w = s[sorted_idx[k]]

3. PREDICT(x_test):
     ≈∑ = fÃÇ(x_test)
     RETURN [≈∑_j - qÃÉ_w, ≈∑_j + qÃÉ_w] for j=1,...,h

Adaptation: Recent errors weighted more ‚Üí handles drift


ALGORITHM 3: Multivariate Conformal (Marginal)
--------------------------------------------------------------------------------
Input: Calibration set, model fÃÇ, Œ±, d features
Output: Per-feature prediction intervals

1. FOR k = 1 to d DO:  # For each feature
     FOR t = 1 to n DO:
       s_t^{(k)} = max_{j=1,...,h} |y_{t+j,k} - fÃÇ(x_t)_{j,k}|
     END FOR
     qÃÉ^{(k)} = quantile_{1-Œ±}({s_1^{(k)}, ..., s_n^{(k)}})
   END FOR

2. PREDICT(x_test):
     ≈∑ = fÃÇ(x_test)  # Shape: (h, d)
     FOR k = 1 to d DO:
       interval_k = [≈∑_{j,k} - qÃÉ^{(k)}, ≈∑_{j,k} + qÃÉ^{(k)}] for j=1,...,h
     END FOR
     RETURN intervals for all features

Efficiency: Different interval widths per feature


THEORETICAL RESULTS
================================================================================

1. FINITE-SAMPLE COVERAGE GUARANTEE
--------------------------------------------------------------------------------

Theorem (Exact Coverage - Exchangeable):
    Under exchangeability, for any Œ± ‚àà (0,1):
    
    P(y_{n+1} ‚àà C(x_{n+1})) ‚â• 1 - Œ±
    
    with equality if ties have probability 0.

Proof Sketch:
    Augmented sequence z_1, ..., z_n, z_{n+1} is exchangeable
    ‚Üí Rank of z_{n+1} is uniform over {1, ..., n+1}
    ‚Üí P(rank > ‚åà(1-Œ±)(n+1)‚åâ) ‚â§ Œ±


2. APPROXIMATE COVERAGE - TIME SERIES
--------------------------------------------------------------------------------

Theorem (Œ≤-Mixing):
    Under Œ≤-mixing with Œ≤(m) ‚â§ C¬∑m^{-Œ≥}, if n, m ‚Üí ‚àû:
    
    |P(y_{n+1} ‚àà C(x_{n+1})) - (1-Œ±)| ‚â§ A/‚àön + B¬∑Œ≤(m)
    
    Where A, B are constants depending on score distribution.

Implication:
    - Large calibration set (n) ‚Üí better coverage
    - Fast mixing (large Œ≥) ‚Üí better coverage
    - Tradeoff: larger m reduces Œ≤(m) but needs larger n


3. INTERVAL WIDTH ANALYSIS
--------------------------------------------------------------------------------

Expected Interval Width:
    E[width(C)] = 2¬∑E[qÃÉ_{1-Œ±}] ‚âà 2¬∑quantile_{1-Œ±}(|Œµ|)
    
    Where Œµ = prediction error distribution

Efficiency:
    Informally efficient if width ‚âà 2¬∑quantile_{1-Œ±} of error distribution
    ‚Üí Adaptive weighting improves efficiency under drift

Conditional Coverage:
    Ideally: P(y ‚àà C | x) ‚â• 1 - Œ± for all x
    Split conformal: Only marginal coverage (averaged over x)
    ‚Üí Need full conformal or localized methods for conditional


PRACTICAL CONSIDERATIONS
================================================================================

1. CALIBRATION SET SIZE
--------------------------------------------------------------------------------

Minimum Samples:
    n_cal ‚â• 1/(2Œ±¬≤) for Œ±-level coverage with high confidence
    
    Example: Œ± = 0.1 ‚Üí need n_cal ‚â• 50

Recommended:
    n_cal ‚â• 1000 for stable quantile estimation
    Larger for multivariate (d features) ‚Üí need d¬∑1000

Data Split:
    Train: 60%, Validation: 10%, Calibration: 15%, Test: 15%


2. SCORE FUNCTION CHOICES
--------------------------------------------------------------------------------

Absolute Error:
    s = |y - ≈∑|
    ‚Üí Symmetric intervals

Quantile Score:
    s_Œ±(y, ≈∑) = (Œ± - ùüô{y < ≈∑})¬∑(y - ≈∑)
    ‚Üí Asymmetric intervals (e.g., for skewed distributions)

Normalized Score:
    s = |y - ≈∑| / œÉÃÇ(x)
    Where œÉÃÇ(x) = estimated prediction variance
    ‚Üí Adaptive interval width based on uncertainty

CQR (Conformalized Quantile Regression):
    s = max(q_low - y, y - q_high)
    Where q_low, q_high from quantile regression
    ‚Üí More efficient than absolute error


3. HYPERPARAMETER TUNING
--------------------------------------------------------------------------------

Significance Level Œ±:
    Common choices: 0.05, 0.1, 0.2
    Higher Œ± ‚Üí narrower intervals, lower coverage

Decay Parameter œÑ (Adaptive):
    œÑ = n/10: Heavy weighting of recent data
    œÑ = n/5: Moderate adaptation
    œÑ = n/2: Slow adaptation
    
    Tune via cross-validation on coverage + width tradeoff

Horizon h:
    Longer h ‚Üí wider intervals (accumulating uncertainty)
    May need h-dependent Œ±: Œ±_h = Œ±¬∑‚àöh (heuristic)


4. ONLINE RECALIBRATION
--------------------------------------------------------------------------------

Rolling Window:
    Maintain last W observations for calibration
    Recompute qÃÉ every K predictions
    
    W = 500-1000 typical
    K = 10-100 typical

Sequential Update:
    Add new (y_true, ≈∑) to calibration set
    Remove oldest observation
    ‚Üí Efficient online quantile tracking algorithms

Trigger Recalibration When:
    - Coverage drops below (1-Œ±) - Œ¥
    - Interval widths increase significantly
    - Detected distribution shift


IMPLEMENTATION FORMULAS
================================================================================

Weighted Quantile (Efficient):
--------------------------------------------------------------------------------
Given: scores s_1, ..., s_n with weights w_1, ..., w_n

1. sorted_idx = argsort(s)
2. s_sorted = s[sorted_idx]
3. w_sorted = w[sorted_idx]
4. cum_weights = cumsum(w_sorted)
5. total_weight = sum(w)
6. threshold = (1-Œ±)¬∑total_weight
7. k = argmin{cum_weights[i] ‚â• threshold}
8. qÃÉ = s_sorted[k]


Exponential Decay Weights:
--------------------------------------------------------------------------------
For observation at time t, current time T:

Linear decay:
    w_t = exp(-Œª(T-t))  where Œª = 1/œÑ

Gaussian decay:
    w_t = exp(-(T-t)¬≤/(2œÑ¬≤))

Polynomial decay:
    w_t = (1 + (T-t))^{-Œ≥}  where Œ≥ > 0


Bootstrap Conformal (Computational):
--------------------------------------------------------------------------------
For computational stability with small calibration sets:

1. FOR b = 1 to B DO:
     Sample n observations with replacement
     Compute qÃÉ_b on bootstrap sample
   END FOR

2. qÃÉ_final = median({qÃÉ_1, ..., qÃÉ_B})

Reduces variance of quantile estimate


COMPLEXITY SUMMARY
================================================================================

Operation              | Time Complexity | Space Complexity
-----------------------|-----------------|------------------
Calibration (n samples)| O(n¬∑h¬∑d)       | O(n)
Quantile computation   | O(n log n)      | O(n)
Single prediction      | O(h¬∑d)          | O(h¬∑d)
Weighted quantile      | O(n log n)      | O(n)
Online update          | O(log n)        | O(n)

Where:
- n = calibration set size
- h = forecast horizon
- d = number of features


COMPARISON: CONFORMAL vs BAYESIAN UNCERTAINTY
================================================================================

Conformal Prediction:
+ Finite-sample guarantees (not asymptotic)
+ Model-agnostic (works with any fÃÇ)
+ No assumptions on data distribution
+ Computationally cheap (just quantile)
- Only marginal coverage (not conditional)
- Requires held-out calibration set
- Intervals may be conservative

Bayesian Methods:
+ Conditional coverage P(y|x)
+ Full posterior distribution
+ Principled uncertainty quantification
- Requires model specification (priors)
- Computationally expensive (sampling)
- Asymptotic guarantees only
- Model misspecification issues


KEY MATHEMATICAL PROPERTIES
================================================================================

1. Distribution-Free:
   No assumptions on y|x distribution ‚Üí works for any data

2. Finite-Sample Validity:
   Coverage guarantee holds for any n (not just n‚Üí‚àû)

3. Calibration Set Independence:
   Prediction intervals don't depend on test point x (marginal)
   ‚Üí Same width for all x in split conformal

4. Monotonicity:
   Smaller Œ± ‚Üí wider intervals ‚Üí higher coverage

5. Symmetry (for absolute error score):
   Intervals symmetric around point prediction

6. Efficiency:
   Interval width proportional to quantile of error distribution
   ‚Üí Nearly optimal under correct model specification


PRACTICAL METRICS
================================================================================

Empirical Coverage:
    coverage = (1/n_test)¬∑Œ£_{i=1}^{n_test} ùüô{y_i ‚àà C(x_i)}
    
    Should be ‚â• 1 - Œ±

Average Interval Width:
    width_avg = (1/n_test)¬∑Œ£_{i=1}^{n_test} (upper_i - lower_i)
    
    Smaller is better (efficiency)

Coverage-Width Tradeoff:
    Efficiency = coverage / width_avg
    
    Higher is better

Winkler Score (Interval Score):
    IS_i = width_i + (2/Œ±)¬∑(lower_i - y_i)¬∑ùüô{y_i < lower_i}
                    + (2/Œ±)¬∑(y_i - upper_i)¬∑ùüô{y_i > upper_i}
    
    Lower is better (penalizes width + miscoverage)

